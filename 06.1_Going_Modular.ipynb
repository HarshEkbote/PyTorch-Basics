{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Modular\n",
    "\n",
    "* This note book consists of cell mode code.\n",
    "* The notebook 06.2 Going Modular consists of the python scripts to run the model in terminal using a single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find image directory .Creating the directory....\n",
      "Data Downloaded\n",
      "File Unzipped!!\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "#Define paths\n",
    "data_path=Path('data/')\n",
    "image_path=data_path/'pizza_sushi_steak'\n",
    "\n",
    "#Create the image folder if sdoes not exists\n",
    "if image_path.is_dir():\n",
    "  print(f\"Directory {image_path} already exixts!\")\n",
    "else:\n",
    "  print(\"Did not find image directory .Creating the directory....\")\n",
    "  image_path.mkdir(parents=True,exist_ok=True)\n",
    "  \n",
    "#Get the image data from github and write\n",
    "with open(data_path/'pizza_sushi_steak.zip','wb') as f:\n",
    "  request=requests.get('https://github.com/HarshEkbote/PyTorch-Basics/raw/main/data/pizza_steak_sushi.zip')\n",
    "  f.write(request.content)\n",
    "  print('Data Downloaded')\n",
    "\n",
    "#Unzip the file contents\n",
    "with zipfile.ZipFile(data_path/'pizza_sushi_steak.zip','r') as zip_ref:\n",
    "  zip_ref.extractall(image_path)\n",
    "  print('File Unzipped!!')\n",
    "\n",
    "#Remove the zipfile\n",
    "os.remove(data_path/'pizza_sushi_steak.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_sushi_steak/train'),\n",
       " WindowsPath('data/pizza_sushi_steak/test'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir=image_path/'train'\n",
    "test_dir=image_path/'test'\n",
    "\n",
    "train_dir,test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Datasets\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 225\n",
      "    Root location: data\\pizza_sushi_steak\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           )\n",
      "\n",
      "Test Dataset\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 75\n",
      "    Root location: data\\pizza_sushi_steak\\test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_transforms=transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data=datasets.ImageFolder(root=train_dir,\n",
    "                                transform=data_transforms,\n",
    "                                target_transform=None)\n",
    "\n",
    "test_data=datasets.ImageFolder(root=test_dir,\n",
    "                                transform=data_transforms)\n",
    "\n",
    "print(f\"Train Datasets\\n{train_data}\\n\\nTest Dataset\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name=train_data.classes\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pizza': 0, 'steak': 1, 'sushi': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict=train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 75)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1f984c3f250>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1f984c3eb30>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE=32\n",
    "\n",
    "train_dataloader=DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "\n",
    "test_dataloader=DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([32, 3, 64, 64])\n",
      "Label shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "img,label=next(iter(train_dataloader))\n",
    "print(f\"Image shape: {img.shape}\\nLabel shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model -> TinyVgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "  def __init__(self,input_shape:int,hidden_units:int,output_shape:int):\n",
    "    super().__init__()\n",
    "    #Block 1\n",
    "    self.block1=nn.Sequential(\n",
    "        nn.Conv2d(in_channels=input_shape,out_channels=hidden_units,kernel_size=3,stride=1,padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,padding=0,stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    )\n",
    "    #Block 2\n",
    "    self.block2=nn.Sequential(\n",
    "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,stride=1,padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,padding=0,stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    )\n",
    "    #Classifier\n",
    "    self.classifier=nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=hidden_units*13*13,out_features=output_shape)\n",
    "    )\n",
    "\n",
    "  def forward(self,x):\n",
    "    # x=self.block1(x)\n",
    "    # print(x.shape)\n",
    "    # x=self.block2(x)\n",
    "    # print(x.shape)\n",
    "    # x=self.classifier(x)\n",
    "    # print(x.shape)\n",
    "    return self.classifier(self.block2(self.block1(x)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#Initialize the model\n",
    "model0=TinyVGG(input_shape=3,hidden_units=10,output_shape=len(class_name))\n",
    "model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits:\n",
      "tensor([[ 0.0208, -0.0020,  0.0095]])\n",
      "\n",
      "Output prediction probabilities:\n",
      "tensor([[0.3371, 0.3295, 0.3333]])\n",
      "\n",
      "Output prediction label:\n",
      "tensor([0])\n",
      "\n",
      "Actual label:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Trial run to get the intermidiate size of tensor\n",
    "img_batch, label_batch=next(iter(train_dataloader))\n",
    "img_single,label_single=img_batch[0].unsqueeze(dim=0),label_batch[0]\n",
    "\n",
    "model0.eval()\n",
    "with torch.inference_mode():\n",
    "  pred=model0(img_single.to(device))\n",
    "\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def train_step(model:nn.Module,dataloader:torch.utils.data.DataLoader,loss_fn:torch.nn.Module,optimizer:torch.optim.Optimizer,device:torch.device)->Tuple[float,float]:\n",
    "  model.train()\n",
    "\n",
    "  train_loss,train_acc=0,0\n",
    "  for batch,(x,y) in enumerate(dataloader):\n",
    "    x,y=x.to(device),y.to(device)\n",
    "\n",
    "    y_pred=model(x)\n",
    "\n",
    "    loss=loss_fn(y_pred,y)\n",
    "    train_loss+=loss.item()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
    "    train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n",
    "\n",
    "  train_loss=train_loss/len(dataloader)\n",
    "  train_acc=train_acc/len(dataloader)\n",
    "  return train_loss,train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model:nn.Module,dataloader:torch.utils.data.DataLoader,loss_fn:torch.nn.Module,device:torch.device)->Tuple[float,float]:\n",
    "  model.eval()\n",
    "  test_loss,test_acc=0,0\n",
    "  with torch.inference_mode():\n",
    "    for batch,(x,y) in enumerate(dataloader):\n",
    "      x,y=x.to(device),y.to(device)\n",
    "\n",
    "      test_pred_logits=model(x)\n",
    "\n",
    "      loss=loss_fn(test_pred_logits,y)\n",
    "      test_loss+=loss.item()\n",
    "\n",
    "      test_pred_label=test_pred_logits.argmax(dim=1)\n",
    "      test_acc+=((test_pred_label==y).sum().item()/len(test_pred_label))\n",
    "\n",
    "  test_loss=test_loss/len(dataloader)\n",
    "  test_acc=test_acc/len(dataloader)\n",
    "\n",
    "  return test_loss,test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinig the Train and Test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict,List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "def train(model:torch.nn.Module,train_datalaoder:torch.utils.data.DataLoader,\n",
    "          test_dataloader:torch.utils.data.DataLoader,optimizer:torch.optim.Optimizer,loss_fn:torch.nn.Module,epochs:int,device:torch.device=device):\n",
    "  \n",
    "  results={\n",
    "      'train_loss':[],\n",
    "      'train_acc':[],\n",
    "      'test_loss':[],\n",
    "      'test_acc':[]\n",
    "  }\n",
    "\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    train_loss,train_acc=train_step(model,train_dataloader,loss_fn,optimizer,device)\n",
    "    test_loss,test_acc=test_step(model,test_dataloader,loss_fn,device)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch+1}\",\n",
    "        f\"train_loss:{train_loss:.4f} |\"\n",
    "        f\"train_acc: {train_acc:.2f} |\"\n",
    "        f\"test_loss:{test_loss:.4f} |\"\n",
    "        f\"test_acc: {test_acc:.2f} |\")\n",
    "    \n",
    "    results['train_loss'].append(train_loss)\n",
    "    results['train_acc'].append(train_acc)\n",
    "    results['test_loss'].append(test_loss)\n",
    "    results['test_acc'].append(test_acc)\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Function to Save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def save_model(model:torch.nn.Module,target_dir:str,model_name:str):\n",
    "  target_dir_path=Path(target_dir)\n",
    "  target_dir_path.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "  assert model_name.endswith('.pth') or model_name.endswith('.pt'), 'model must be saved in .pth or .pt format'\n",
    "  model_save_path=target_dir_path/model_name\n",
    "\n",
    "  print(f\"[INFO] Saving the mode to {model_save_path}\")\n",
    "  torch.save(obj=model.state_dict(),f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Evaluate and Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:11<00:47, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 train_loss:1.2058 |train_acc: 0.34 |test_loss:1.1186 |test_acc: 0.54 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:20<00:30, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 train_loss:1.1685 |train_acc: 0.28 |test_loss:1.0783 |test_acc: 0.54 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:29<00:18,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 train_loss:1.1069 |train_acc: 0.32 |test_loss:1.0955 |test_acc: 0.42 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:37<00:09,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 train_loss:1.0997 |train_acc: 0.31 |test_loss:1.0937 |test_acc: 0.54 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:45<00:00,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 train_loss:1.0979 |train_acc: 0.40 |test_loss:1.0958 |test_acc: 0.54 |\n",
      "[INFO] Total training time: 45.974 seconds\n",
      "[INFO] Saving the mode to models\\cell_mode_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "NUM_EPOCHS=5\n",
    "\n",
    "model0=TinyVGG(input_shape=3,hidden_units=10,output_shape=len(class_name)).to(device)\n",
    "\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(params=model0.parameters(),lr=0.01)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start_time=timer()\n",
    "\n",
    "model0_results=train(model=model0,\n",
    "                     train_datalaoder=train_dataloader,\n",
    "                     test_dataloader=test_dataloader,\n",
    "                     optimizer=optimizer,\n",
    "                     loss_fn=loss_fn,epochs=NUM_EPOCHS,device=device)\n",
    "\n",
    "end_time=timer()\n",
    "print(f'[INFO] Total training time: {end_time-start_time:.3f} seconds')\n",
    "\n",
    "\n",
    "save_model(model=model0,target_dir='models',model_name=\"cell_mode_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
